{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFA1OpsandLogReg.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paruliansaragi/DL-Notebooks/blob/master/TFA1OpsandLogReg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idqyrQQmJQac",
        "colab_type": "code",
        "outputId": "1573f37f-300f-499c-9e65-ba407a96db49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "Simple exercises to get used to TensorFlow API\n",
        "You should thoroughly test your code.\n",
        "TensorFlow's official documentation should be your best friend here\n",
        "CS20: \"TensorFlow for Deep Learning Research\"\n",
        "cs20.stanford.edu\n",
        "Created by Chip Huyen (chiphuyen@cs.stanford.edu)\n",
        "\"\"\"\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "sess = tf.InteractiveSession()\n",
        "###############################################################################\n",
        "# 1a: Create two random 0-d tensors x and y of any distribution.\n",
        "# Create a TensorFlow object that returns x + y if x > y, and x - y otherwise.\n",
        "# Hint: look up tf.cond()\n",
        "# I do the first problem for you\n",
        "###############################################################################\n",
        "\n",
        "x = tf.random_uniform([])  # Empty array as shape creates a scalar.\n",
        "y = tf.random_uniform([])\n",
        "out = tf.cond(tf.greater(x, y), lambda: x + y, lambda: x - y)\n",
        "print(sess.run(out))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.5983182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moY7Ux4SJmZ7",
        "colab_type": "code",
        "outputId": "48db45b7-ff1c-4363-9ffc-df67fea123aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "###############################################################################\n",
        "# 1b: Create two 0-d tensors x and y randomly selected from the range [-1, 1).\n",
        "# Return x + y if x < y, x - y if x > y, 0 otherwise.\n",
        "# Hint: Look up tf.case().\n",
        "###############################################################################\n",
        "\n",
        "# YOUR CODE\n",
        "# So the tf.random_uniform() takes in shape, a minval which we can use as -1 and a maxval as 1)\n",
        "# Use shape=[] for 0-d tensor when using rand uni\n",
        "x = tf.random_uniform(shape=[], minval=-1, maxval=1, dtype=tf.float32)#Correct\n",
        "y = tf.random_uniform(shape=[], minval=-1, maxval=1, dtype=tf.float32)\n",
        "# Using cond\n",
        "# tf.cond seems to take in two ternary lambda functions based on the first initial condition\n",
        "# ret = tf.cond(x < y, lambda: tf.subtract(x, y), lambda: 0)\n",
        "# Using tf.case()\n",
        "# takes in a boolean scalar tensor and a python callable that creates the tensors to be returned\n",
        "# if the bool is True.\n",
        "def py_callable1(): return tf.add(x, y) #if not a function then returns err\n",
        "def py_callable2(): return tf.zeros(1)\n",
        "#out = tf.case({tf.less(x, y): py_callable1, tf.greater(x, y): py_callable2})\n",
        "#out = tf.case([(tf.less(x, y), py_callable1)], default=py_callable2)\n",
        "out = tf.case({tf.less(x, y): lambda: tf.add(x, y),\n",
        "              tf.greater(x, y): lambda: tf.subtract(x,y)},\n",
        "             default=lambda: tf.constant(0.0), exclusive=True)\n",
        "print(sess.run(out))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.23227906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xrs7zSKdObmH",
        "colab_type": "code",
        "outputId": "9fcafa9a-2698-4b1e-afd2-a858219ce53f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "###############################################################################\n",
        "# 1c: Create the tensor x of the value [[0, -2, -1], [0, 1, 2]] \n",
        "# and y as a tensor of zeros with the same shape as x.\n",
        "# Return a boolean tensor that yields Trues if x equals y element-wise.\n",
        "# Hint: Look up tf.equal().\n",
        "###############################################################################\n",
        "\n",
        "# YOUR CODE\n",
        "x = tf.constant([[0, -2, -1],[0, 1, 2]], dtype=tf.float32)\n",
        "y = tf.zeros(shape=[2,3], dtype=tf.float32)\n",
        "out = tf.equal(x, y) #takes an x tensor and a y tensor and a name and returns a tensor of bools if x == y\n",
        "print(sess.run(out))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ True False False]\n",
            " [ True False False]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w85mPBV8Prgh",
        "colab_type": "code",
        "outputId": "ca608517-854c-4f84-b3d2-1ca657351586",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "###############################################################################\n",
        "# 1d: Create the tensor x of value \n",
        "# [29.05088806,  27.61298943,  31.19073486,  29.35532951,\n",
        "#  30.97266006,  26.67541885,  38.08450317,  20.74983215,\n",
        "#  34.94445419,  34.45999146,  29.06485367,  36.01657104,\n",
        "#  27.88236427,  20.56035233,  30.20379066,  29.51215172,\n",
        "#  33.71149445,  28.59134293,  36.05556488,  28.66994858].\n",
        "# Get the indices of elements in x whose values are greater than 30.\n",
        "# Hint: Use tf.where().\n",
        "# Then extract elements whose values are greater than 30.\n",
        "# Hint: Use tf.gather().\n",
        "###############################################################################\n",
        "\n",
        "# YOUR CODE\n",
        "x = tf.constant([29.05088806,  27.61298943,  31.19073486,  29.35532951,\n",
        "                 30.97266006,  26.67541885,  38.08450317,  20.74983215,\n",
        "                 34.94445419,  34.45999146,  29.06485367,  36.01657104,\n",
        "                 27.88236427,  20.56035233,  30.20379066,  29.51215172,\n",
        "                 33.71149445,  28.59134293,  36.05556488,  28.66994858], dtype=tf.float32)\n",
        "greater = tf.where(tf.greater(x, 30))#takes in a condition, \n",
        "# and x or y and returns elements either from x or y depending on your condition\n",
        "#tf.gather, gathers slices from params axis, axis according to indices\n",
        "gathered = tf.gather(x, greater) \n",
        "# params: a tensor from which to gather values\n",
        "# indices: a tensor, \n",
        "# axis: axis in params to gather indices from\n",
        "print(sess.run(gathered))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[31.190735]\n",
            " [30.97266 ]\n",
            " [38.084503]\n",
            " [34.944454]\n",
            " [34.45999 ]\n",
            " [36.01657 ]\n",
            " [30.20379 ]\n",
            " [33.711494]\n",
            " [36.055565]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKs42dCSRL7J",
        "colab_type": "code",
        "outputId": "0b06032d-be0a-4276-9e7c-1649f74de1b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "###############################################################################\n",
        "# 1e: Create a diagnoal 2-d tensor of size 6 x 6 with the diagonal values of 1,\n",
        "# 2, ..., 6\n",
        "# Hint: Use tf.range() and tf.diag().\n",
        "###############################################################################\n",
        "\n",
        "# YOUR CODE\n",
        "# tf.linalg.diag() returns a bathed diagonal tensor with a given batched diagonal values\n",
        "# given a diagonal, returns a tensor with the diagonal and everything else padded with zeros\n",
        "vals = tf.range(1, 7, 1) # should return [1, 2, 3, 4, 5, 6]\n",
        "# now create a diagonal from those values on the diag and 0 everywhere else\n",
        "diag = tf.diag(vals)\n",
        "print(sess.run(diag))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 0 0 0 0 0]\n",
            " [0 2 0 0 0 0]\n",
            " [0 0 3 0 0 0]\n",
            " [0 0 0 4 0 0]\n",
            " [0 0 0 0 5 0]\n",
            " [0 0 0 0 0 6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUW5uNk9SQAG",
        "colab_type": "code",
        "outputId": "a761c57b-d5e4-460c-9918-42fdfc077871",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "###############################################################################\n",
        "# 1f: Create a random 2-d tensor of size 10 x 10 from any distribution.\n",
        "# Calculate its determinant.\n",
        "# Hint: Look at tf.matrix_determinant().\n",
        "###############################################################################\n",
        "\n",
        "# YOUR CODE\n",
        "rand = tf.random_normal(shape=[10,10], mean=10, stddev=1)\n",
        "deter = tf.matrix_determinant(rand)#Computes the determinant of one or more square matrices.\n",
        "print(sess.run(deter))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-13092.184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1wh7MQ2TBZQ",
        "colab_type": "code",
        "outputId": "4310a83e-bae1-4cea-b660-5f34f08aa33e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "###############################################################################\n",
        "# 1g: Create tensor x with value [5, 2, 3, 5, 10, 6, 2, 3, 4, 2, 1, 1, 0, 9].\n",
        "# Return the unique elements in x\n",
        "# Hint: use tf.unique(). Keep in mind that tf.unique() returns a tuple.\n",
        "###############################################################################\n",
        "\n",
        "# YOUR CODE\n",
        "x = tf.constant([5, 2, 3, 5, 10, 6, 2, 3, 4, 2, 1, 1, 0, 9])\n",
        "uniq = tf.unique(x) #finds unique elements in a 1-D tensor\n",
        "# returns a tensor y containing all unique elements of x sorted in the same order they occurred.\n",
        "# also returns idx tensor that contains index of each value of in output.\n",
        "# so uniq will be 5:0, 2:1, 3:2 ...\n",
        "# lets use zip to unpack \n",
        "val,idx = uniq\n",
        "print(sess.run(val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 5  2  3 10  6  4  1  0  9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHkEbdZEI07P",
        "colab_type": "code",
        "outputId": "43e950d4-b0cb-4fad-800c-cc7b37c60fb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "###############################################################################\n",
        "# 1h: Create two tensors x and y of shape 300 from any normal distribution,\n",
        "# as long as they are from the same distribution.\n",
        "# Use tf.cond() to return:\n",
        "# - The mean squared error of (x - y) if the average of all elements in (x - y)\n",
        "#   is negative, or\n",
        "# - The sum of absolute value of all elements in the tensor (x - y) otherwise.\n",
        "# Hint: see the Huber loss function in the lecture slides 3.\n",
        "###############################################################################\n",
        "\n",
        "# YOUR CODE\n",
        "\n",
        "x = tf.random_normal(shape=[300], mean=25, stddev=1)\n",
        "y = tf.random_normal(shape=[300], mean=25, stddev=1)\n",
        "#tf.reduce_mean() computes the mean of elements across dimensions of a tensor.\n",
        "# returns a reduced tensor\n",
        "avg = tf.reduce_mean(x - y)\n",
        "#tf.reduce_sum() computes the sum of elements across dimensions of a tensor. \n",
        "# returns a reduced tensor\n",
        "def f1(): return tf.reduce_mean(tf.square(x - y))\n",
        "#tf.abs() computes the absolute value of a tensor (non-zero value). \n",
        "def f2(): return tf.reduce_sum(tf.abs(x - y))\n",
        "out = tf.cond(avg < 0, f1, f2)\n",
        "print(sess.run(out))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "327.55774\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA4RYgb6XXO0",
        "colab_type": "code",
        "outputId": "aa52d896-8c6f-45b9-b58c-835a90c475b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/chiphuyen/stanford-tensorflow-tutorials/master/examples/utils.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-25 09:35:49--  https://raw.githubusercontent.com/chiphuyen/stanford-tensorflow-tutorials/master/examples/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5167 (5.0K) [text/plain]\n",
            "Saving to: ‘utils.py’\n",
            "\n",
            "\rutils.py              0%[                    ]       0  --.-KB/s               \rutils.py            100%[===================>]   5.05K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-01-25 09:35:49 (83.0 MB/s) - ‘utils.py’ saved [5167/5167]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuMsGXozXHAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Starter code for simple logistic regression model for MNIST\n",
        "with tf.data module\n",
        "MNIST dataset: yann.lecun.com/exdb/mnist/\n",
        "Created by Chip Huyen (chiphuyen@cs.stanford.edu)\n",
        "CS20: \"TensorFlow for Deep Learning Research\"\n",
        "cs20.stanford.edu\n",
        "Lecture 03\n",
        "\"\"\"\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "import utils\n",
        "\n",
        "# Define paramaters for the model\n",
        "learning_rate = 0.01\n",
        "batch_size = 128\n",
        "n_epochs = 30\n",
        "n_train = 60000\n",
        "n_test = 10000\n",
        "\n",
        "# Step 1: Read in data\n",
        "mnist_folder = 'data/mnist'\n",
        "utils.download_mnist(mnist_folder)\n",
        "train, val, test = utils.read_mnist(mnist_folder, flatten=True)\n",
        "\n",
        "# Step 2: Create datasets and iterator\n",
        "# create training Dataset and batch it\n",
        "train_data = tf.data.Dataset.from_tensor_slices(train)\n",
        "train_data = train_data.shuffle(10000) # if you want to shuffle your data\n",
        "train_data = train_data.batch(batch_size)\n",
        "\n",
        "# create testing Dataset and batch it\n",
        "# dont shuffle test set\n",
        "test_data = tf.data.Dataset.from_tensor_slices(test)\n",
        "test_data = test_data.batch(batch_size)\n",
        "#############################\n",
        "########## TO DO ############\n",
        "#############################\n",
        "\n",
        "# create one iterator and initialize it with different datasets\n",
        "iterator = tf.data.Iterator.from_structure(train_data.output_types, \n",
        "                                           train_data.output_shapes)\n",
        "img, label = iterator.get_next()\n",
        "\n",
        "train_init = iterator.make_initializer(train_data)\t# initializer for train_data\n",
        "test_init = iterator.make_initializer(test_data)\t# initializer for train_data\n",
        "\n",
        "# Step 3: create weights and bias\n",
        "# w is initialized to random variables with mean of 0, stddev of 0.01\n",
        "# b is initialized to 0\n",
        "# shape of w depends on the dimension of X and Y so that Y = tf.matmul(X, w)\n",
        "# shape of b depends on Y\n",
        "w = tf.get_variable(name='weights', shape=(784,10), initializer=tf.random_normal_initializer(0, 0.01))\n",
        "b = tf.get_variable(name='bias', shape=(1,10), initializer=tf.random_zeros_initializer())\n",
        "#############################\n",
        "########## TO DO ############\n",
        "#############################\n",
        "\n",
        "# Step 4: build model\n",
        "# the model that returns the logits.\n",
        "# this logits will be later passed through softmax layer\n",
        "logits = tf.matmul(img, w) + b\n",
        "#############################\n",
        "########## TO DO ############\n",
        "#############################\n",
        "\n",
        "\n",
        "# Step 5: define loss function\n",
        "# use cross entropy of softmax of logits as the loss function\n",
        "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=label, name='entropy')\n",
        "loss = tf.reduce_mean(entropy, name='loss') #computes the mean over all the examples in the batch \n",
        "#############################\n",
        "########## TO DO ############\n",
        "#############################\n",
        "\n",
        "\n",
        "# Step 6: define optimizer\n",
        "# using Adamn Optimizer with pre-defined learning rate to minimize loss\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
        "#############################\n",
        "########## TO DO ############\n",
        "#############################\n",
        "\n",
        "\n",
        "# Step 7: calculate accuracy with test set\n",
        "preds = tf.nn.softmax(logits)\n",
        "correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(label, 1))\n",
        "accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
        "\n",
        "writer = tf.summary.FileWriter('./graphs/logreg', tf.get_default_graph())\n",
        "with tf.Session() as sess:\n",
        "   \n",
        "    start_time = time.time()\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    # train the model n_epochs times\n",
        "    for i in range(n_epochs): \t\n",
        "        sess.run(train_init)\t# drawing samples from train_data\n",
        "        total_loss = 0\n",
        "        n_batches = 0\n",
        "        try:\n",
        "            while True:\n",
        "                _, l = sess.run([optimizer, loss])\n",
        "                total_loss += l\n",
        "                n_batches += 1\n",
        "        except tf.errors.OutOfRangeError:\n",
        "            pass\n",
        "        print('Average loss epoch {0}: {1}'.format(i, total_loss/n_batches))\n",
        "    print('Total time: {0} seconds'.format(time.time() - start_time))\n",
        "\n",
        "    # test the model\n",
        "    sess.run(test_init)\t\t\t# drawing samples from test_data\n",
        "    total_correct_preds = 0\n",
        "    try:\n",
        "        while True:\n",
        "            accuracy_batch = sess.run(accuracy)\n",
        "            total_correct_preds += accuracy_batch\n",
        "    except tf.errors.OutOfRangeError:\n",
        "        pass\n",
        "\n",
        "    print('Accuracy {0}'.format(total_correct_preds/n_test))\n",
        "writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}