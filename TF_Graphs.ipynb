{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF Graphs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paruliansaragi/DL-Notebooks/blob/master/TF_Graphs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22bgg4dYcQxJ",
        "colab_type": "text"
      },
      "source": [
        "# Tensorflow\n",
        "\n",
        "Tensorflow is a powerful OOS lib for numerical computation, fine-tuned for large-scale ML. Its basic principle is simple,\n",
        "First you define in Python a graph of computations to perform and then TensorFlow takes that graph and runs it efficiently\n",
        "using optimized C++ code.\n",
        "\n",
        "![alt text](https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0901.png)\n",
        "\n",
        "Fig 9.1 A simple computational graph\n",
        "\n",
        "Most importantly, you can break up the graph into several chunks and run them in parallel across multiple CPUs or GPUs (as show in \n",
        "fi 9.2). TF can train a NN with millions of params on a training set of billions of instances with millions of features each.\n",
        "TF was developed by Google Brain and powers many of Google's large scale services, such as Google Cloud Speech, Google Photos, Google Search.\n",
        "\n",
        "\n",
        "![alt text](https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0902.png)\n",
        "Fig 9.2 Parallel computation on multiple CPUs/GPUs/servers\n",
        "TF highlights;\n",
        "\n",
        "-python api called TF.learn, compatible with Scikit-learn. \n",
        "\n",
        "-TF-slim to simplify building, training and evaluating NN's.\n",
        "\n",
        "-Other high level APIs such as Keras/Pretty Tensor\n",
        "\n",
        "-There is a C++ API to define your own high-performance operations\n",
        "\n",
        "-It provides several advanced optimization nodes to search for the parameters that minimize the cost function. This is very easy to use\n",
        "since TF automatically takes care of computing the gradients of the functions you define. This is called automatic differentiating.\n",
        "\n",
        "-TensorBoard is a great tool for visualising through the computational graph, view learning curves etc.\n",
        "\n",
        "-TensorFLow graph\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y6g4aUgdR4M",
        "colab_type": "text"
      },
      "source": [
        "# Creating your first graph and running it in a session\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxj3hcTxbxHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Just disables the warning, doesn't enable AVX/FMA\n",
        "#import os\n",
        "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "x = tf.Variable(3, name=\"x\")\n",
        "y = tf.Variable(4, name=\"y\")\n",
        "f = x*x*y + y + 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCTN0Ro2d4Hk",
        "colab_type": "text"
      },
      "source": [
        "The code doesnt actually perform any computation , it just creates a computational graph. Even the variables aren't initialised yet.\n",
        "To evaluate this graph, you need to open a tensorflow session and use it to initialize the variables and evaluate f. \n",
        "A TF session takes care of placing the operations onto devices such as CPUs and GPUs and running them, and it holds all the \n",
        "variable values. The following code creates a session, initializes the variables, and evaluates, and f then closes the session\n",
        "(which frees up resources):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C-a3F-2d4xg",
        "colab_type": "code",
        "outputId": "264d2f62-a2e9-4af8-b7d2-01baeaad8541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sess = tf.Session()\n",
        "sess.run(x.initializer)\n",
        "sess.run(y.initializer)\n",
        "result = sess.run(f)\n",
        "print(result)\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYMVmGued602",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Having to repeat sess.run() all the time is a bit annoying but there's a better way\n",
        "with tf.Session() as sess:\n",
        "\tx.initializer.run()\n",
        "\ty.initializer.run()\n",
        "\tresult = f.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmvzA2e7e9bL",
        "colab_type": "text"
      },
      "source": [
        "Inside the with block, the session is set as the default session. Calling x.initializer.run() is equivalent to calling\n",
        "tf.get_default_session().run(x.initializer).\n",
        "Instead of manually running the init for every single variable, you can use the global_variables_initializer() function.\n",
        "This creates a node in the graph to init all vars when it is run:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQCFF--Se5Up",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer() #prepare an init node"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1vMOajqfH_r",
        "colab_type": "code",
        "outputId": "3fe8d2b4-8d1c-41d3-bb81-e7911e709440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "\tinit.run() #actually inits all the vars\n",
        "\tresult = f.eval()\n",
        "\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_CE1n17fFVX",
        "colab_type": "text"
      },
      "source": [
        "You may prefer to create an InteractiveSession. the difference being that when an interactivesession is created it\n",
        "automatically sets itself as the default session, so you dont need a with block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9FI3QNWfLxz",
        "colab_type": "code",
        "outputId": "734d3695-24b3-45ed-b743-058040103061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sess = tf.InteractiveSession()\n",
        "init.run()\n",
        "result = f.eval()\n",
        "print(result)\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-eXWPlkfPqB",
        "colab_type": "text"
      },
      "source": [
        "A tf program is typically split into two parts: the first part builds a computation graph (the construction phase),\n",
        "and the second part runs it (the execution phase). \n",
        "The construction phase builds a computational graph representing the ML model and the computations required to train it. \n",
        "The execution phase generally runs a loop that evaluates a training step repeatedly, gradually improving model params. \n",
        "\n",
        "# Managing Graphs \n",
        "\n",
        "Any node you create is auto added to the default graph:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBX3KpFcfNdW",
        "colab_type": "code",
        "outputId": "1aece5be-8a89-4093-8ffd-3d81a2b160c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x1 = tf.Variable(1)\n",
        "x1.graph is tf.get_default_graph()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4xJCjL1fgr2",
        "colab_type": "text"
      },
      "source": [
        "You may want to manage multiple independet graphs. You can do this by creating a new Graph and temporarily making it default\n",
        "graph inside a with block:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwKXcOxXfhKK",
        "colab_type": "code",
        "outputId": "1a69f2ba-2b39-4595-8786-79c327ebd97f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "\tx2 = tf.Variable(2)\n",
        "\n",
        "print(x2.graph is graph)\n",
        "print(x2.graph is tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bahjTCwVflM2",
        "colab_type": "text"
      },
      "source": [
        "# Lifecycle of a Node Value \n",
        "\n",
        "When you evaluate a node, TF auto determines the set of nodes that it depends on and it evaluates these nodes first. \n",
        "For example, consider the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un-Wur-OfqzF",
        "colab_type": "code",
        "outputId": "82da6ed4-5e08-468a-eca7-9f3568cc4acc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "w = tf.constant(3)\n",
        "x = w + 2\n",
        "y = x + 5\n",
        "z = x * 3\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\tprint(y.eval()) # 10\n",
        "\tprint(z.eval()) # 15"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mw6xLH3pfwgD",
        "colab_type": "text"
      },
      "source": [
        "First, this code defines a very simple graph. Then it starts a session and runs the graph to evaluate y: TensorFlow automatically\n",
        "detects that y depends on x, which depends on w, so it first evaluates w, then x, then y, and returns the val of y. Finally,\n",
        "the code runs the graph to evaluate z. Once again, TensorFlow detects that it must first evaluate w and x. It is important to note\n",
        "that it will not reuse the result of the previous evaluation of w and x. In short, the preceding code evaluates w and x twice. \n",
        "\n",
        "All node values are dropped between graph runs, except variable values, which are maintained by the session across graph runs.\n",
        "A variable starts its life when its initializer is run, and it ends when the session is closed. \n",
        "\n",
        "If you want to evaluate y and z efficiently, without evaluating w and x twice as in the previous code, you must ask TF to eval\n",
        "both y and z in just one graph run:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE9WVS7XfyMc",
        "colab_type": "code",
        "outputId": "671ad28e-1482-44d3-99c5-3951b702f79e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "\ty_val, z_val = sess.run([y, z])\n",
        "\tprint(y_val)\n",
        "\tprint(z_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxukfH_Xf0ns",
        "colab_type": "text"
      },
      "source": [
        "In single process TF, multiple sessions do not share any state, even if they reuse the same graph(each session would have its own\n",
        "copy of every variable). Variable state is stored on the servers, not sessions, so multiple sessions can share the same vars.\n",
        "\n",
        "# Linear Regression with TensorFlow \n",
        "\n",
        "TF operations called ops, can take any number of inputs and produce any number of outputs. For example, the addition and multiplication\n",
        "ops each take two inputs and produce one output. Constants and variables take no input theyre called source ops. \n",
        "The inputs and outputs are multidimensional arrays, called tensors. Just like Numpy arrays, tensors have a type and shape.\n",
        "In fact, in the Python API tensors are simply represented by Numpy ndarrays. They typically contain floats, but you can also use them\n",
        "to carry strings (arbitrary byte arrays).\n",
        "\n",
        "So far we have only dealt with tensors contained a single scalar value, but you can perform computations on arrays of any shape. \n",
        "The following code manipulates 2D arrays to perform lin reg. Starts by fetching the dataset; then it adds an extra bias input \n",
        "feature (x0 = 1) to all training instances(it does so using Numpy so it runs immediately); then it creates two TF constant nodes,\n",
        "X and y, to hold this data and the targets, and it uses matrix operations to define theta. These functions transpose(), matmul(),\n",
        "and  matrix_inverse() - do not perform any computations immediately, instead they create nodes in the graph that will perform\n",
        "them when the graph is run. You may recognise that the definition of theta corresponds to the Normal equation. Finally, the code\n",
        "creates a session and uses it to evaluate theta. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_rbrUgPf1U8",
        "colab_type": "code",
        "outputId": "33b4ab22-75f6-4f23-e88c-a79b1b454efc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np \n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "m, n = housing.data.shape\n",
        "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
        "\n",
        "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
        "XT = tf.transpose(X)\n",
        "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\ttheta_value = theta.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgmwQEKSgKq9",
        "colab_type": "text"
      },
      "source": [
        "# Implementing Gradient Descent\n",
        "\n",
        "We will use Batch gradient descent. When using GD remember to normalize the input feature vectors to speed up training.\n",
        "\n",
        "# Manually Computing the gradients\n",
        "\n",
        "\n",
        "\n",
        "*   the random_uniform() function creates a node in the graph that will generate a tensor containing random values, given its shape and value range, much like NumPy's rand() function\n",
        "*   The assign() function creates a node that will assign a new value to a variable. In this case it implement a batch gradient descent step. \n",
        "\n",
        "\n",
        "*   The main loop executes the training step over and over agant (n_epochs times), and every 100 iterations it prints out the current Mean Squared Error (MSE). \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efmXyc8miylP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaled_housing_data = scaler.fit_transform(housing.data)\n",
        "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHWV8bPqhCOt",
        "colab_type": "code",
        "outputId": "00bd010f-2301-4e2e-e22c-bd2d7c9a8f24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# to make this notebook's output stable across runs\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "n_epochs = 1000\n",
        "learning_rate = 0.01\n",
        "\n",
        "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
        "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
        "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        if epoch % 100 == 0:\n",
        "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
        "        sess.run(training_op)\n",
        "    \n",
        "    best_theta = theta.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Epoch', 0, 'MSE =', 9.161543)\n",
            "('Epoch', 100, 'MSE =', 9.161543)\n",
            "('Epoch', 200, 'MSE =', 9.161543)\n",
            "('Epoch', 300, 'MSE =', 9.161543)\n",
            "('Epoch', 400, 'MSE =', 9.161543)\n",
            "('Epoch', 500, 'MSE =', 9.161543)\n",
            "('Epoch', 600, 'MSE =', 9.161543)\n",
            "('Epoch', 700, 'MSE =', 9.161543)\n",
            "('Epoch', 800, 'MSE =', 9.161543)\n",
            "('Epoch', 900, 'MSE =', 9.161543)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Cb1K6lxb63E",
        "colab_type": "text"
      },
      "source": [
        "**Using autodiff**\n",
        "\n",
        "It automatically computes the gradients. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up-9rl5niKS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gradients = tf.gradients(mse, [theta])[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr4WIa7pclOd",
        "colab_type": "text"
      },
      "source": [
        "The gradients() function takes an op(in this case mse) and a list of variables(in this case theta), and creates a list of ops (one per variable) to compute the gradients of the op with regards to each variable. \n",
        "\n",
        "**Using an Optimizer**\n",
        "\n",
        "You can replace the preceding gradients = ... and training_op = ... with the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0MP6GuAcbbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "training_op = optimizer.minimize(mse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMqSZhrMdXvv",
        "colab_type": "text"
      },
      "source": [
        "You can use different optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PZJOhqQdb2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}