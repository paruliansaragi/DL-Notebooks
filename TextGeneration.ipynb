{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextGeneration.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paruliansaragi/DL-Notebooks/blob/master/TextGeneration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJNqJ8paJId7",
        "colab_type": "code",
        "outputId": "d1df1b12-db26-478f-bfab-27f0cfd1e45f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa4G1yXcKzmq",
        "colab_type": "code",
        "outputId": "8358e942-3de0-4cd2-ed30-2f09341680ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!unzip alllines.txt.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  alllines.txt.zip\n",
            "  inflating: alllines.txt            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVEl7ZdVJ_Fj",
        "colab_type": "code",
        "outputId": "4252cee9-442d-4958-9339-b6aa4b3c2627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "f = open(\"alllines.txt\", \"r\")\n",
        "print(f.read(500))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"ACT I\"\n",
            "\"SCENE I. London. The palace.\"\n",
            "\"Enter KING HENRY, LORD JOHN OF LANCASTER, the EARL of WESTMORELAND, SIR WALTER BLUNT, and others\"\n",
            "\"So shaken as we are, so wan with care,\"\n",
            "\"Find we a time for frighted peace to pant,\"\n",
            "\"And breathe short-winded accents of new broils\"\n",
            "\"To be commenced in strands afar remote.\"\n",
            "\"No more the thirsty entrance of this soil\"\n",
            "\"Shall daub her lips with her own children's blood,\"\n",
            "\"Nor more shall trenching war channel her fields,\"\n",
            "\"Nor bruise her flowerets with the ar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2fZn-9YKWq3",
        "colab_type": "code",
        "outputId": "5adf5a5f-4f91-4e41-f07c-23ac05ba701f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "text = open(\"alllines.txt\", \"r\").read().lower()[:500000]\n",
        "print('Corpus length:', len(text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus length: 500000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7yISZhtLIMb",
        "colab_type": "code",
        "outputId": "a375cae7-1719-4f17-eb86-743abbd5b289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "text[:50]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"act i\"\\n\"scene i. london. the palace.\"\\n\"enter king'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf--8pF5Ludd",
        "colab_type": "code",
        "outputId": "c916a88d-0691-463b-c981-606887172bd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Length of extracted character sequences\n",
        "maxlen = 60\n",
        "\n",
        "# We sample a new sequence every `step` characters\n",
        "step = 3\n",
        "\n",
        "# This holds our extracted sequences\n",
        "sentences = []\n",
        "\n",
        "# This holds the targets (the follow-up characters)\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('Number of sequences:', len(sentences))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sequences: 166647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VpnZfp4Cnxo",
        "colab_type": "code",
        "outputId": "e7247681-5618-4089-aa5e-9a9c736d2e05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "sentences[:5]#creates 60 character long sentence lengths whilst appending i before the max length"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\"act i\"\\n\"scene i. london. the palace.\"\\n\"enter king henry, lo',\n",
              " 't i\"\\n\"scene i. london. the palace.\"\\n\"enter king henry, lord ',\n",
              " '\"\\n\"scene i. london. the palace.\"\\n\"enter king henry, lord joh',\n",
              " 'scene i. london. the palace.\"\\n\"enter king henry, lord john o',\n",
              " 'ne i. london. the palace.\"\\n\"enter king henry, lord john of l']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv77i2aOCTkF",
        "colab_type": "code",
        "outputId": "11331c32-eadd-4707-e402-2a860e7f733f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# List of unique characters in the corpus\n",
        "chars = sorted(list(set(text)))\n",
        "#set()#Build an unordered collection of unique elements.\n",
        "print('Unique characters:', len(chars))\n",
        "# Dictionary mapping unique characters to their index in `chars`\n",
        "char_indices = dict((char, chars.index(char)) for char in chars)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique characters: 44\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoNMa6zUDtOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GX-zj5XMCXwQ",
        "colab_type": "code",
        "outputId": "bf256121-cc25-449e-ea35-ef5eebceb7a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Next, one-hot encode the characters into binary arrays.\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6A62hl0CfF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import layers\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(layers.Dense(len(chars), activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_5XncTzGRNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upJC4WWFGRw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL_fAUa_NMFZ",
        "colab_type": "code",
        "outputId": "dee59fc0-fb9a-4877-a5f1-bcd025301b1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4415
        }
      },
      "source": [
        "import random\n",
        "import sys\n",
        "\n",
        "for epoch in range(1, 60):\n",
        "    print('epoch', epoch)\n",
        "    # Fit the model for 1 epoch on the available training data\n",
        "    model.fit(x, y,\n",
        "              batch_size=128,\n",
        "              epochs=1)\n",
        "\n",
        "    # Select a text seed at random\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    generated_text = text[start_index: start_index + maxlen]\n",
        "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
        "\n",
        "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('------ temperature:', temperature)\n",
        "        sys.stdout.write(generated_text)\n",
        "\n",
        "        # We generate 400 characters\n",
        "        for i in range(400):\n",
        "            sampled = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(generated_text):\n",
        "                sampled[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(sampled, verbose=0)[0]\n",
        "            next_index = sample(preds, temperature)\n",
        "            next_char = chars[next_index]\n",
        "\n",
        "            generated_text += next_char\n",
        "            generated_text = generated_text[1:]\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1\n",
            "Epoch 1/1\n",
            "166647/166647 [==============================] - 205s 1ms/step - loss: 3.3201\n",
            "--- Generating with seed: \"nry and dame margaret kneel'd to me\"\n",
            "\"and on my head did set\"\n",
            "------ temperature: 0.2\n",
            "nry and dame margaret kneel'd to me\"\n",
            "\"and on my head did setaa aa haaaaooahaaaoa aoh aaohaahaoa a a aaahaohaooahaaoaahaaaaa  aaoaaaaaahoaahaa aahaa haaa  aaoaah aaaa oaahaooaaaaaaaaaaaaaaoaaohhaaooaahaaaaaaaaaaaa aaaaa   haaaaaa  oaaaaaa oaoao aaaaoaaaa aoaoaaaaaaaahoaaaoooaaaaa  aaaaaaa aaahoaaahahaahahoahaahaaohaaaooaaaaaaoa aahhahhaaaa aoaao aaa aooaaaaoaaaooo ahaoaaaaaaoaahaaaa aoooaa aaaaaa aahaaa aaa.aha ahoo o aaaa haaooho aaahoa haaaoaoaoaaaaaaoaaa\n",
            "------ temperature: 0.5\n",
            "ahaaa aaa.aha ahoo o aaaa haaooho aaahoa haaaoaoaoaaaaaaoaaaa\n",
            "nh  a  ohahoh . anoadaa.  aha  ah aah hh hhaao oaa   eaahhi ooaarah a oao haaaaooaaahaaa.eaena h  ah h taoah ato ahohhao ooaaoaoaaooaaaa  aaheotoe oaoahhaoaaa holao\n",
            "oaa\n",
            "hh aahooo\n",
            "a aaaoteoao aoha a caaaaaoaa al a  haaaaohooh aaahhahhmal eimaaeeaoa nat taaahhhh aaa aloa oa  oeo o d aaaht ohhaa  hoaaheh avr\n",
            "ahahaaaaaahaaa ho raaoaaoaao \"khaothhoaaa h hoooaa  hoaooooahaha\n",
            "oloaoo roa ohaahohdaooaaao\n",
            "------ temperature: 1.0\n",
            "haothhoaaa h hoooaa  hoaooooahaha\n",
            "oloaoo roa ohaahohdaooaaaoho\n",
            "tnaatm r ho \n",
            "  a a than odh\" e ail .oa\"thootaoao\n",
            "a\"eo aot\n",
            "odaahao'.    bh\n",
            "eahbat.aaoeoaenag   oi,. aoahhs\n",
            "i\n",
            ".du\"gaoo de l hh.aupcaaoao hhahmenhvoa h\n",
            "cn. aahht.aoan\n",
            "eeaoh\n",
            "taarhntdt heha hhboiee\n",
            " ae norani\"   aouacoooh hnais \"ooah\n",
            "oau eoor hah  ahdl oaeh\n",
            ". ac hooo.rhtda\n",
            "rd  o a. ahho, ao afofoal.aoadsh eloh\"hhmdor  ho\n",
            "t ahhc  .onamreatheaaaarie aem a nou\n",
            ".aeo r caetoee  .hna\" oolotgiaor\"hcdo hko\n",
            "\n",
            "------ temperature: 1.2\n",
            "aaaarie aem a nou\n",
            ".aeo r caetoee  .hna\" oolotgiaor\"hcdo hko\n",
            "cahvhhdlah ma,a.oodaent\n",
            "\n",
            "oeor\n",
            "ha  aalt.amlohhgenbloanbh cmnedvohrab  hafdoatamyra .ee.e\" 'egw.roc. e aoo a .ac.,hla ia'\"otnaee   obet\"ah oal\"ch'a o n  haleaopiolah\"et. fhi\n",
            "maao r. motaaicll\n",
            "dien ,awrtp odaohvaotioind\n",
            "thoarh tap\"at ua,'o\n",
            "hcaaa\n",
            "oec\"o\n",
            "chhlaf oiaaihuangn,s\"\n",
            "eni'\n",
            "o'c\n",
            "t.oca cnsh\n",
            "hh ioar  ouo\" l a hrheon ehdo.tabtvaah mohraoo  rroaod\"\"ha.t  tu v\"ao hdt orne.\n",
            "hchhbaoh\"  t ge\n",
            " paltdlveo . \n",
            "epoch 2\n",
            "Epoch 1/1\n",
            "166647/166647 [==============================] - 205s 1ms/step - loss: 3.3146\n",
            "--- Generating with seed: \"dirt\"\n",
            "\"troubles the silver spring where england drinks.\"\n",
            "\"no\"\n",
            "------ temperature: 0.2\n",
            "dirt\"\n",
            "\"troubles the silver spring where england drinks.\"\n",
            "\"no  h   s  h hhh shhh  sh   h h"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "h s hh   h    hshh s shh hhs h hhh  hhh  h hhh h h h  h shshhhhhth hs   h   hh  hs thh  s    hs shh shhsh  h     h h  hhshh hh hh h  shh h  hhh  h       h shhhhhh  h hsshth shhhs s     sh   h s   s hhh t h h   hh hh h  h s   h  hhshshsh h   hhhss s hs   hh  hh  hhh hh  hh s   h hhh  hs ss  h  hhhsh s h  s  h h ss h s  ss   hh  sh hhs   s s  h shs   s hsh ths   shh     \n",
            "------ temperature: 0.5\n",
            " ss h s  ss   hh  sh hhs   s s  h shs   s hsh ths   shh     t  httnn sh  s hshhs    hshh heti\n",
            "rstsohd,hs  a sdsdht  snhst ht  hh  hdst  hh t\n",
            "hsssh u t  stsshnfhhhssod \n",
            " \" td  , hssh r eh  hhrsshr,hnhrsun s nhhfh\"tis ssshtuhshbrhshhhh ethtrs h bf t hsth\"rrd srs hhh srt  httst sss rrsssf\n",
            "\n",
            " n\"rt t\" r hthh\n",
            "shtoh trhrsrsshh h hss hfhssrtthuhhs tc enf\n",
            " hrseetnsnh h hshs e    tsn   sh,   hh h ss  tshs shsr tsr\n",
            " r nshs hssth,her \"\n",
            " \n",
            "ees, h   st hhwh rrhhe \"rt\n",
            "i \"h\n",
            "------ temperature: 1.0\n",
            "sr tsr\n",
            " r nshs hssth,her \"\n",
            " \n",
            "ees, h   st hhwh rrhhe \"rt\n",
            "i \"hh \"hbt h\n",
            "a \n",
            "r\n",
            "sh\n",
            "v th\"sdhht la hn asnttuel \"s\"u  am rwsisn\n",
            "rufht \"useamys n\"nesetidd.r,\" h  ttnthnhf \n",
            "t tbns hi  rbhe\"sei gnn rbhstnhsss \n",
            "ras,wn\"rksms ms\"ets\n",
            " suhh,l r,ig\n",
            "r   ihri'pdv hrs u astdca rehtnhsh\" s ndnsea uahindhrbetesa\"\n",
            " htheoie saot asnsahhtteht hfe s\"  rt,\n",
            "unru,\"mr d \"shu:phsk\n",
            "i\n",
            "r.i sl ws s,srh enh nubh  thaiao t,ddhhd\n",
            "n htstt  en  idbdshbmsdt  musrh h-dh,h\n",
            "iyhs\n",
            "u strw\n",
            "mhs'htrrsu  s \n",
            "------ temperature: 1.2\n",
            "tt  en  idbdshbmsdt  musrh h-dh,h\n",
            "iyhs\n",
            "u strw\n",
            "mhs'htrrsu  s  n r \n",
            "  ,.,  tm?oth  urvs .shaeb\n",
            "os.m\"snr\n",
            "h  e trht\n",
            " r\"oeiiwshgnsi\"r rnne,s \"lodssn,ssc.dhw \"te \"ti \"tlrni   \",ctfcont \"w isd-u \n",
            "ots :ham\"-ptr,hdtb e\n",
            "hm g,h snn w vsinssnsabdtittdtnh,dhuse,u,sngeh y\n",
            "r,bre\n",
            ",atesh mrhnsrtthot  hcs tpsteisrs\n",
            "is,en t tlhhihtrtvt dai ,sbnrrhodmk hresrs\n",
            "g fhhegiebhu.\n",
            "\"b'sr.krnaar sbh syo hhat-ladsnannhuhhrhtthtth,h\"ueu e\"y,mh ted \" s fnh.d\"ih vsheh hhs,',n ,,t\"h\"lh,eiua\n",
            "epoch 3\n",
            "Epoch 1/1\n",
            "166647/166647 [==============================] - 205s 1ms/step - loss: 3.3137\n",
            "--- Generating with seed: \"his, 'tis 'bona terra, mala gens.'\"\n",
            "\"away with him, away wit\"\n",
            "------ temperature: 0.2\n",
            "his, 'tis 'bona terra, mala gens.'\"\n",
            "\"away with him, away witt tttt t tt s        ttr t  t  t  ttt  t tt t      r  tt t tttt tt tr  st t  \"t s t     rt  st t t t tss     sttt rtt\"t stt   t\" t t   t t trts rtttt tt  tttt t   tt  tt t t t ttstt     \" ttt t  ttt st  t t \"rtte t   t  t   t   r\"  tt r    \"  \"t st     ttt ttt    ttt tt \" tt ttt  t   trt        st  tt   rt   ttttt  t tt t\" s   tt tt t     ttt       tt     t  t  st  rt   t  et t t    tt stttt ttts \n",
            "------ temperature: 0.5\n",
            " ttt       tt     t  t  st  rt   t  et t t    tt stttt ttts etth trsser\"s res\"retgtissttr tsr  serteht tt  s et t\"ttttt\"e\" ts\" r  th tt s t\"\"t t n r\" gs\"t sr   s stt rst  r ktrtt  r \"yr  ttthtl\"stsrtrnt t\"ttr res td\" etrtttt  n e et g trt  t t reh\"e\"r t\"  tsso t nsrsttr\" s\"t.tht ir trse s      gnet\"r \"ttt\n",
            "ttr  t  sttns e t  eh\" y t  s tr  r i\"ttd t\"ttdt \" e, s t l \"t tse  t   i  tt  tt tnhtet t shse ty ttsaossht resr\" \"t\" e\"trterhyt\"rt r\"\"ss se ttt\"a rtrtt\n",
            "------ temperature: 1.0\n",
            "se ty ttsaossht resr\" \"t\" e\"trterhyt\"rt r\"\"ss se ttt\"a rtrttitdt yleestrss resbss w se\"sbsotekeacstttts\"an \"nothse\"s \n",
            "s,et.rs l\n",
            "ergtphh\n",
            " \"yett e\"\"a t so\"reiut  tthh\n",
            "de\"u'or:s te   rhhswle,n \"st rrsit s ts tntrjue eer,\"\"sedt esmi\"ehecn\".td\" n t\n",
            "thee\"gs\"\n",
            "sic\"\"r \n",
            "ek\"n rtscefstrthr stg t\" \n",
            "trhsthm\"sts  \n",
            "r rrr nr\"d ri lsetfet\n",
            "ahrsrg\"ederhsnss \"i\"rgtt  e stsr ds\"hn  meals  , s\"is,d \"t\n",
            "lt orwu yrigste s\",,ontt rsed:grtho h ww nhe ,stto.\n",
            "stt rtrts, \"trnseh tt\n",
            "th ,\n",
            "------ temperature: 1.2\n",
            ",,ontt rsed:grtho h ww nhe ,stto.\n",
            "stt rtrts, \"trnseh tt\n",
            "th ,r\"s ,mgs\"rte eterrmtteysed.rctct\"\n",
            ".c\"e\"mt tmuk\"ashheehmyttst s\"rtp nh.tmfr py\"eehrahtktkt\n",
            "ri\"gds teprupshtwl  ' wv \"s nt \n",
            "rht\"tpnost\"tesda rtto t\"uteltrormvse \"rt\"e\",rcw\"nrs\n",
            "erttosbne srrk\"\" wd\n",
            "u  \"sd tsrt\"etdpte\"uhf\"rchs  rwnsett so o txok   twtt it \n",
            "rre .tt,st d tr\"h tm\".fdm et.gtur\"swl\" s kew\n",
            "wt.est\"\n",
            "loo.e a\"ed  \"lgtehc\n",
            "t n\"yeg\"srdtyhr\" yetndys brsoststt ha  ed\"r \"\n",
            "t:gau ttoakantytbt\"b'rnt ,ubt\n",
            "epoch 4\n",
            "Epoch 1/1\n",
            "166647/166647 [==============================] - 205s 1ms/step - loss: 3.3161\n",
            "--- Generating with seed: \"veal'd herself,\"\n",
            "\"and, whereas i was black and swart before,\"\n",
            "------ temperature: 0.2\n",
            "veal'd herself,\"\n",
            "\"and, whereas i was black and swart before, e e e   e       ee  ee e     e     e  e   ee     ee e  eee   e ee         e   e  e  e          e     e      eee   eeee   ee eee   e   e  eee e ee   e         e     e e            ee ee    e e e e   ee  e  e teeee  ee      ee e ee e f   e ee e  ee  efeee  eee     e   e   e      e    e e      e ee    e    e e        e   ee    ee     e e    e   e     ee eee  eeeee  e  e    e    e e e        e  eee e\n",
            "------ temperature: 0.5\n",
            " e   e     ee eee  eeeee  e  e    e    e e e        e  eee eo     he  ea  f eet  e  hes ft o  aee tem oe   omt  e   eee ee  vs t  te t ieteieteeaeeee  ef oe   u eeseeeeefeed  eee d i  af tet e e   f s  fbae htte eeeuaee  eeede   e noe  fa   eeee  eeat  a t e   he   te    ee f o  \n",
            " heee \n",
            "f f.  ee a a  o   ee tt   s a   oet efo earoe t  h     feneo e  cte teee eae ef ee   e ee   h ee\n",
            "eaeee oero t ne      e \n",
            "eme eee f   e h tseo sxeo   t  e e   f ee   ooeea  \n",
            "------ temperature: 1.0\n",
            "      e \n",
            "eme eee f   e h tseo sxeo   t  e e   f ee   ooeea   ahiae hhteet ees   loo rhfa tv fdaafme hceics ot ch asycr ademm evoaahioemlia me tett afttidhothtge \n",
            "ft oo  ot,taoe rtsoe \"oeeto\n",
            "l homxaed eaefoteefue\n",
            " o ot ab   tftm\n",
            " eere  y eox  gthwvtea t g  \n",
            "itfmo  exda ften\n",
            "!oha\n",
            "tthf t vehstota ee ftexfal\n",
            "hfm\n",
            "   eaf  ef.ees   tooaedt mofih\n",
            "te a hhoe\n",
            "\n",
            "mdn sefc hapuh  aeuhciea  utth to  feeadteueetb fo a\"hd hrm aawfhs\n",
            "tfe iimlf\n",
            "!ua cofei no\" aabxffey  ouanh  \n",
            "------ temperature: 1.2\n",
            "fo a\"hd hrm aawfhs\n",
            "tfe iimlf\n",
            "!ua cofei no\" aabxffey  ouanh  eo ed ase\n",
            "eoboohibbouesl lst sroefre r   nxwt!c! ttff ssymffaaamaa erdefo\n",
            "cr hhsmmmaveuot hehheh cfaae  - n anlisstfuhebefswt eeh eet   ae ecamideefio eevltenh eovu be e uie ooe d  euefs rntav\n",
            "aal ehmfd e na rti e ee ietagee ev\n",
            "a teenoas  etw a et reuotaou d veedh,a seoeaoe\n",
            "o,fe\n",
            "ptcenehsioeeme dsames eyuos tsbhiy ee ltoeo e\n",
            "   u tltuaufe ap , aaef afd  mtve\"mdxetld,fe ogene ma  lmfoa mn  \n",
            " d,mhfwo\n",
            "epoch 5\n",
            "Epoch 1/1\n",
            " 87040/166647 [==============>...............] - ETA: 1:38 - loss: 3.3162"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-9486ed95c0ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     model.fit(x, y,\n\u001b[1;32m      8\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m               epochs=1)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Select a text seed at random\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79rZVPHRNipt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}